# ğŸ§  e-BrAIn.Tech - Portal do Centro de ExcelÃªncia em IA

**VersÃ£o 2.0 - Arquitetura Modular Completa**

O e-BrAIn.Tech Ã© o portal oficial do Centro de ExcelÃªncia em InteligÃªncia Artificial da ContaX-Brain-Tech. Ele permite acesso integrado e contextual a mÃºltiplos modelos de IA, oferecendo funcionalidades de revisÃ£o de cÃ³digo, geraÃ§Ã£o de texto, sumarizaÃ§Ã£o, criaÃ§Ã£o de imagens, speech-to-text e muito mais.

Com arquitetura modular e suporte a mÃºltiplos providers de LLM, o portal oferece flexibilidade total, histÃ³rico das Ãºltimas 90 interaÃ§Ãµes e uma experiÃªncia amigÃ¡vel e eficiente.

## ğŸ—ï¸ Arquitetura

A aplicaÃ§Ã£o segue os princÃ­pios de **Clean Architecture** com separaÃ§Ã£o clara de responsabilidades:

```
app/
â”œâ”€â”€ core/                    # Interfaces e abstraÃ§Ãµes centrais
â”‚   â”œâ”€â”€ llm_interface.py     # Interface abstrata para providers
â”‚   â”œâ”€â”€ context_manager.py   # Gerenciamento de contexto
â”‚   â”œâ”€â”€ history_manager.py   # HistÃ³rico em SQLite
â”‚   â””â”€â”€ config_loader.py     # Carregamento de configuraÃ§Ãµes
â”œâ”€â”€ providers/               # ImplementaÃ§Ãµes de providers
â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”œâ”€â”€ meta_provider.py
â”‚   â”œâ”€â”€ ollama_provider.py
â”‚   â”œâ”€â”€ bedrock_provider.py
â”‚   â”œâ”€â”€ google_provider.py
â”‚   â””â”€â”€ provider_factory.py
â”œâ”€â”€ features/                # Funcionalidades modulares
â”‚   â”œâ”€â”€ chat.py
â”‚   â”œâ”€â”€ code_review.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â””â”€â”€ image_generation.py
â””â”€â”€ frontend/                # Interface Streamlit
    â””â”€â”€ main_app.py
```

## ğŸš€ CaracterÃ­sticas

### Providers Suportados

- âœ… **OpenAI** - GPT-4o, GPT-4 Turbo, DALL-E, Whisper
- âœ… **Anthropic** - Claude 3.5 Sonnet, Claude 3 Opus
- âœ… **Meta** - LLaMA 3.1 (via Ollama ou API)
- âœ… **Ollama** - Modelos locais (Llama, Mistral, etc.)
- âœ… **AWS Bedrock** - Claude via Bedrock
- âœ… **Google** - Gemini 1.5 Pro

### Funcionalidades

1. **ğŸ’¬ Chat IA** - ConversaÃ§Ã£o contextual com IA
2. **ğŸ” Code Reviewer** - RevisÃ£o detalhada de cÃ³digo
3. **ğŸ“ Summarizer** - SumarizaÃ§Ã£o de textos longos
4. **ğŸ¤ Speech-to-Text** - TranscriÃ§Ã£o de Ã¡udio
5. **ğŸ¨ Image Generator** - GeraÃ§Ã£o de imagens via DALL-E
6. **ğŸ“Š HistÃ³rico** - VisualizaÃ§Ã£o de interaÃ§Ãµes anteriores
7. **âš™ï¸ ConfiguraÃ§Ãµes** - Gerenciamento de configuraÃ§Ãµes

## ğŸ“‹ PrÃ©-requisitos

- Python 3.11 ou superior
- Docker (opcional, para containerizaÃ§Ã£o)
- Credenciais para os providers desejados

## ğŸ”§ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: InstalaÃ§Ã£o Local

1. Clone o repositÃ³rio:
```bash
git clone <repository-url>
cd contax-brain
```

2. Crie ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. Instale dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Configure variÃ¡veis de ambiente (crie `.env`):
```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Meta/Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# AWS Bedrock
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=us-east-1
AWS_BEDROCK_MODEL=anthropic.claude-3-5-sonnet-20240620-v1:0

# Google
GOOGLE_API_KEY=...
GOOGLE_MODEL=gemini-1.5-pro
```

5. Execute a aplicaÃ§Ã£o:
```bash
streamlit run main.py
```

### OpÃ§Ã£o 2: Docker

1. Configure variÃ¡veis de ambiente no `.env`

2. Execute com Docker Compose:
```bash
docker-compose up -d
```

3. Acesse em `http://localhost:8501`

## ğŸ“– Uso

### Chat IA

1. Selecione um provider na sidebar
2. VÃ¡ para a aba "ğŸ’¬ Chat IA"
3. Digite sua mensagem e pressione Enter
4. A IA responderÃ¡ mantendo o contexto da conversa

### Code Reviewer

1. VÃ¡ para a aba "ğŸ” Code Reviewer"
2. Cole seu cÃ³digo
3. Selecione a linguagem (opcional)
4. Clique em "Revisar CÃ³digo"

### Summarizer

1. VÃ¡ para a aba "ğŸ“ Summarizer"
2. Cole o texto a ser sumarizado
3. Ajuste o comprimento mÃ¡ximo
4. Clique em "Gerar Resumo"

### Speech-to-Text

1. VÃ¡ para a aba "ğŸ¤ Speech-to-Text"
2. FaÃ§a upload de arquivo de Ã¡udio
3. Clique em "Transcrever Ãudio"

### Image Generator

1. VÃ¡ para a aba "ğŸ¨ Image Generator"
2. Descreva a imagem desejada
3. Selecione o tamanho
4. Clique em "Gerar Imagem"

## ğŸ”’ SeguranÃ§a

- âœ… Credenciais nunca sÃ£o hardcoded
- âœ… VariÃ¡veis de ambiente para configuraÃ§Ã£o
- âœ… Suporte a Secrets Manager no Streamlit Cloud
- âœ… HistÃ³rico armazenado localmente (SQLite)

## ğŸ§ª Testes

Para testar um provider isoladamente:

```python
from app.providers.openai_provider import OpenAIProvider
from app.core.llm_interface import LLMMessage, TaskType

provider = OpenAIProvider()
if provider.is_available():
    messages = [LLMMessage(role="user", content="OlÃ¡!")]
    response = provider.generate_text(messages, TaskType.CHAT)
    print(response.content)
```

## ğŸ“š DocumentaÃ§Ã£o Adicional

- `ARCHITECTURE.md` - Detalhes da arquitetura
- `DEPLOY.md` - Guia de deploy no Streamlit Cloud
- `CHANGELOG.md` - HistÃ³rico de mudanÃ§as

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/NovaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona NovaFeature'`)
4. Push para a branch (`git push origin feature/NovaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© propriedade da Twinn/ContaX.

## ğŸ†˜ Suporte

Para suporte, entre em contato com a equipe de desenvolvimento ou abra uma issue no repositÃ³rio.

---

**e-BrAIn.Tech** - Portal do Centro de ExcelÃªncia em IA | ContaX-Brain-Tech

